# VideoInputSource

## Preface

I think it is well refined now, so I decide to share this plugin here for every end-user who want to retrieve video from capture device or web camera.

It is developed for my work in the beginning. But I think somebody might need this to processing real-time captured video, so I post here and wish I could help anyone who use AviSynth to do some prototyping easily.

One day, I am asked to import and process real-time captured video and merge with video from files in AviSynth for making some prototype.
In the beginning, I grabbed video frame from DirectShowSource() with grf file as input. However, I found that DirectShowSource() won't duplicate or skip frame when some video capture device (ex. webcam) cannot produce next frame ontime. This phenomenon will cause AviSynth's frame feeding slow down while playing AviSynth script.
For this reason, I made a AviSynth source filter which capture video from video capture device. It is based on a simple video capture library named VideoInput.

### videoInput

official webpage: http://www.muonics.net/school/spring05/videoInput/
github: https://github.com/ofTheo/videoInput



## Download

binary (prebuilt with AviSynth SDK 2.5x and VapourSynth R54):
VideoInputSource.x86.dll
VideoInputSource.x64.dll

source:
VideoInputSource from https://github.com/fieliapm/himawari_avs_plugin/



## Usage

The usage of this source filter is as below:

```clike=
VideoInputSource(device_id,connection_type,width,height,"fps_numerator","fps_denominator","num_frames","frame_skip")



# device_id: the n-th number of video capture device in your computer

# connection_type: can be these string: "Composite","S_Video","Tuner","USB".
#     I leave this parameter because videoInput library offer this option.

# width, height: the width and height of frames captured from video capture device.

# fps_numerator, fps_denominator: FPS numerator and denominator.
#     Default is 30/1 (30.0fps)

# num_frames: How many frame will be captured from video capture device.
#     This will tell AviSynth the length of this video source.
#     Default it will be the value which makes video source length become 24 hours.

# frame_skip: enable/disable frame skip while next new frame from video capture device is not ready.
#     Default is true.
#     When encoding is faster than real-time playing speed, please set this to false.
```

For example:

AviSynth script

```clike=
VideoInputSource(0,"Composite",1920,1080,24,1)
```

VapourSynth script

```python=
core.video_input_source.VideoInputSource(0, 'Composite', 1920, 1080, 24, 1)
```

Will grab video from video capture device #0, 1920x1080, 24.0 fps, 24 hours long.



## Appendix

videoInput always output BGR24 packed pixels. For efficiency, current version of VideoInputSource supports RGB24 color format only.
Since I sometimes use VapourSynth for video processing, I might focus on compatibility of VapourSynth in the future.

By the way, It can work with MP_Pipeline very well since I often test this plugin in separate process generated by MP_Pipeline.
However this plugin exclusively accesses to video capture device, so don't create video source from the same video capture device at the same time.
